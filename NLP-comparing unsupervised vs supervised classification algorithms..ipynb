{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preface\n",
    "\n",
    "The code below explores how far one might lean on an unsupervised topic model to classify a document it hasn't seen. \n",
    "\n",
    "\n",
    "The two unsupervised NLP algorithms chosen are Latent Dirieclet Allocation(LDA) and a non-negative matrix factorization algorithm(NMF). For the sake of comparison I also ran a generic supervised classification algorithm on the same data. \n",
    " \n",
    "Four categories were chosen from the 20_newsgroup data set for training and testing. They were as follows(baseball,hockey,guns and lastly the Middle East). \n",
    "\n",
    "The baseline was aproximately .25 for the test data as each category was aproximately 25% of the entire test data set.\n",
    "\n",
    "The unsupervised algorithms had the number of topics manually set to four. This is simplistic given the likely non-exclusivity of topics across categories in any document. Both models trained on just the text data from the four categories but had no idea what category each document was. \n",
    "\n",
    "They are then tested on unseen documents and asked to predict what category each document is. For purposes of simplisticly each category is regared as having one dominant topic. Each time the unsupervised model produces a probability for the four topics per document the document is assigned the topic/category with the highest probabily.  \n",
    "\n",
    "This is asking alot from both unsupervised models but the NMF model did better than baseline but definitely worse than the supervised algorithm. LDA results were volatile which is not too surprsing given its design. I am a huge fan of Andrew Ng who co-designed the original LDA model but this is probably one of the least favorite NLP models to work with.  \n",
    "\n",
    "Results are below. \n",
    "\n",
    "#### References:\n",
    "\n",
    "Greene,Oâ€™Callaghan,Cunningham,(2014): 'How Many Topics? Stability Analysis for Topic Models'\n",
    "https://arxiv.org/abs/1404.4606\n",
    "\n",
    "Blei, Ng, Jorden(2003): Latent Dirichlet ALlocation,   \n",
    "https://ai.stanford.edu/~ang/papers/nips01-lda.pdf\n",
    "\n",
    "#### July 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies \n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "import re, nltk, spacy, gensim\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify topic categories used in analysis\n",
    "cats = ['rec.sport.baseball', 'rec.sport.hockey','talk.politics.guns', 'talk.politics.mideast']  \n",
    "\n",
    "#Get Spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 5110014\n",
    "\n",
    "#Regex to do some pre spacy cleaning, end line, emails and single quotatins removed\n",
    "def clean_data(self):\n",
    "    global cleaned\n",
    "    cleaning = self\n",
    "    cleaned = [re.sub('\\s+', ' ',sent)for sent in cleaning]\n",
    "    cleaned = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in cleaning]\n",
    "    cleaned = [re.sub(\"\\'\", \"\", sent) for sent in cleaning]\n",
    "\n",
    "#Tokenize      \n",
    "def sent_to_words(self):\n",
    "    for sentence in self:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))   \n",
    "         \n",
    "#Lemmatize with Spacy        \n",
    "def lemmatization(texts):  \n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append(\" \".join([token.lemma_ for token in doc]))\n",
    "                          \n",
    "    return texts_out     \n",
    "\n",
    "#Fetch and process train data\n",
    "def train_data(): \n",
    "    global tr_data,data_tr  \n",
    "     \n",
    "    data_tr = fetch_20newsgroups(subset='train', categories=cats,shuffle=True, random_state=1,\n",
    "                             remove=('headers','footers', 'quotes'))     \n",
    "    clean_data(data_tr.data)         \n",
    "    data_words = list(sent_to_words(cleaned))\n",
    "    tr_data = lemmatization(data_words)\n",
    "    \n",
    "#Fetch and process test data    \n",
    "def test_data(): \n",
    "    global te_data ,data_te     \n",
    "    data_te = fetch_20newsgroups(subset='test', categories=cats,shuffle=True, random_state=1,\n",
    "                             remove=('headers','footers', 'quotes'))     \n",
    "    clean_data(data_te.data)         \n",
    "    data_words = list(sent_to_words(cleaned))\n",
    "    te_data = lemmatization(data_words)\n",
    "\n",
    "#Fetch data and do some cleaning    \n",
    "def get_data():\n",
    "    train_data()\n",
    "    test_data()\n",
    "    \n",
    "#Get tfidf vectors    \n",
    "def get_tfidf():    \n",
    "    global tfidf_train,tfidf_test\n",
    "    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=3000,ngram_range=(1, 1),\n",
    "                                   stop_words='english')\n",
    "    tfidf_train = vectorizer.fit_transform(tr_data)\n",
    "    tfidf_test = vectorizer.transform(te_data) \n",
    "\n",
    "#get term frequency vectorizor\n",
    "def get_tfs():\n",
    "    global tf_train,tf_test\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=3000,ngram_range=(1, 1),stop_words='english') \n",
    "    tf_train = tf_vectorizer.fit_transform(tr_data)\n",
    "    tf_test = tf_vectorizer.transform(te_data)\n",
    "    \n",
    "#Vectorize data    \n",
    "def vectorize_data():\n",
    "    get_tfidf()\n",
    "    get_tfs()\n",
    "\n",
    "#Fetch clean and vectorized data\n",
    "def read_prep_data():\n",
    "    get_data()\n",
    "    vectorize_data()\n",
    "\n",
    "#Pipeline with grid search that optimizes for accuracy across both the transformer and the classifier. \n",
    "def run_supervised_classifier():\n",
    "    parameters = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'tfidf__max_features': (1000,2000,3000),\n",
    "               'clf__alpha': (1e-2, 1e-3)}\n",
    "    svm_clf = Pipeline([('tfidf', TfidfVectorizer()),('clf', SGDClassifier(loss='hinge',\n",
    "         random_state=42,max_iter=500,tol=1e-3))])\n",
    "    gs_clf = GridSearchCV(svm_clf, parameters, cv=5, iid=False, n_jobs=-1)\n",
    "    gs_clf = gs_clf.fit(tr_data,data_tr.target)\n",
    "    print(\"Best parameters from supervised grid search classifier :\")\n",
    "    print(gs_clf.best_params_)\n",
    "    print('')\n",
    "    print(\"Supervised classifier accuracy on test data :\",gs_clf.score(te_data,data_te.target))\n",
    "    \n",
    "#Produces accuracy of unsupervised models\n",
    "def unsup_acc(self): \n",
    "    global d\n",
    "    pred= self.argmax(axis=1)\n",
    "    pred.shape\n",
    "    act= data_te.target\n",
    "    acc_score= pred - act  \n",
    "    corr=[] \n",
    "    for i in acc_score:\n",
    "        if i ==0:\n",
    "            corr.append(i)\n",
    "    c= np.array(corr)\n",
    "    d= (c.shape[0]/act.shape[0]) \n",
    "         \n",
    "#Latent Dirichlet Allocation (LDA model)           \n",
    "def run_lda():      \n",
    "    lda_train = LatentDirichletAllocation(n_components=4, max_iter=1000,\n",
    "                                learning_method='online',random_state=0) \n",
    "    lda_train.fit_transform(tf_train)\n",
    "    lda_test= lda_train.transform(tf_test)\n",
    "    unsup_acc(lda_test)\n",
    "    print('')\n",
    "    print('LDA accuracy :',d)\n",
    "                \n",
    "#Non-negative matrix factorization model  (NMF model)        \n",
    "def run_nnmf():\n",
    "    nnmf = NMF(n_components=4, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', init='nndsvda', max_iter=1000, alpha=.2,\n",
    "          l1_ratio=0.5)\n",
    "    nnmf_train= nnmf.fit_transform(tfidf_train)\n",
    "    nnmf_test = nnmf.transform(tfidf_test) \n",
    "    unsup_acc(nnmf_test)\n",
    "    print('')\n",
    "    print('NMF accuracy :', d)\n",
    "                      \n",
    "            \n",
    "#Baseline check on four labels in the unseen test data\n",
    "def check_baseline(): \n",
    "    ave_label_pc=[]\n",
    "    for i in range(4):\n",
    "        ave_label_pc.append(list(data_te.target).count(i)/data_te.target.shape[0])   \n",
    "        m= np.array(ave_label_pc).mean()\n",
    "    print(\"Baseline check(average percentage of the four labels in test data) :\", m)\n",
    "    print('')   \n",
    "        \n",
    "#Run unsupervised models\n",
    "def run_unsupervised_models():\n",
    "    run_lda() \n",
    "    run_nnmf()  \n",
    "\n",
    "#Main function compares supervised against the two unsupervised models(LDA, NMF)         \n",
    "def model_comparison():\n",
    "    read_prep_data()  \n",
    "    check_baseline()   \n",
    "    run_supervised_classifier()\n",
    "    run_unsupervised_models()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline check(average percentage of the four labels in test data) : 0.25\n",
      "\n",
      "Best parameters from supervised grid search classifier :\n",
      "{'clf__alpha': 0.001, 'tfidf__max_features': 3000, 'tfidf__ngram_range': (1, 1), 'tfidf__use_idf': True}\n",
      "\n",
      "Supervised classifier accuracy on test data : 0.8626302083333334\n",
      "\n",
      "LDA accuracy : 0.044921875\n",
      "\n",
      "NMF accuracy : 0.4290364583333333\n"
     ]
    }
   ],
   "source": [
    "#Run main function to compare the models\n",
    "model_comparison()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
