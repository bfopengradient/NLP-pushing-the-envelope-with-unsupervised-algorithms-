{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preface\n",
    "\n",
    "The code below explores how far one might lean on an unsupervised topic model to classify a document it hasn't seen. \n",
    "\n",
    "\n",
    "The two unsupervised NLP algorithms chosen are Latent Dirichlet Allocation(LDA) and a non-negative matrix factorization algorithm(NMF). For the sake of comparison I also ran a generic supervised classification algorithm on the same data. \n",
    " \n",
    "Four categories were chosen from the 20_newsgroup data set for training and testing. They were as follows:\n",
    "\n",
    "1. Baseball\n",
    "2. Hockey\n",
    "3. Guns \n",
    "4. Middle East \n",
    "\n",
    "The unsupervised algorithms had the number of topics manually set to four. This is simplistic given the likely non-exclusivity of topics across categories in any document. Both models trained on just the text data from the four categories but had no idea what category each document was. \n",
    "\n",
    "They are then tested on unseen documents and asked to predict what category each document is. For the sake of simplistically each category is regarded as having one dominant topic. Each time the unsupervised model produces a probability for the four topics per document the document is assigned the topic/category with the highest probability.  \n",
    "\n",
    "This is asking a lot from both unsupervised models but the NMF model did better than baseline but definitely worse than the supervised algorithm. LDA results were volatile which is not too surprising given its design.  \n",
    "\n",
    "Results are below. \n",
    "\n",
    "#### References:\n",
    "\n",
    "Greene, Oâ€™Callaghan, Cunningham(2014): 'How Many Topics? Stability Analysis for Topic Models'\n",
    "https://arxiv.org/abs/1404.4606\n",
    "\n",
    "Blei, Ng, Jorden(2003): Latent Dirichlet Allocation,   \n",
    "https://ai.stanford.edu/~ang/papers/nips01-lda.pdf\n",
    "\n",
    "#### July 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies \n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "import re, nltk, spacy, gensim\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify topic categories used in analysis\n",
    "cats = ['rec.sport.baseball', 'rec.sport.hockey','talk.politics.guns', 'talk.politics.mideast']\n",
    "target_names = ['Baseball', 'Hockey', 'Guns','Middle East']\n",
    "\n",
    "#Get Spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 5110014\n",
    "\n",
    "#Regex to do some pre spacy cleaning, end line, emails and single quotatins removed\n",
    "def clean_data(self):\n",
    "    global cleaned\n",
    "    cleaning = self\n",
    "    cleaned = [re.sub('\\s+', ' ',sent)for sent in cleaning]\n",
    "    cleaned = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in cleaning]\n",
    "    cleaned = [re.sub(\"\\'\", \"\", sent) for sent in cleaning]\n",
    "\n",
    "#Tokenize      \n",
    "def sent_to_words(self):\n",
    "    for sentence in self:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))   \n",
    "         \n",
    "#Lemmatize with Spacy        \n",
    "def lemmatization(texts):  \n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append(\" \".join([token.lemma_ for token in doc]))                          \n",
    "    return texts_out     \n",
    "\n",
    "#Fetch and process train data\n",
    "def train_data(): \n",
    "    global tr_data,data_tr       \n",
    "    data_tr = fetch_20newsgroups(subset='train', categories=cats,shuffle=True, random_state=1,\n",
    "                             remove=('headers','footers', 'quotes'))     \n",
    "    clean_data(data_tr.data)         \n",
    "    data_words = list(sent_to_words(cleaned))\n",
    "    tr_data = lemmatization(data_words)\n",
    "    \n",
    "#Fetch and process test data    \n",
    "def test_data(): \n",
    "    global te_data ,data_te     \n",
    "    data_te = fetch_20newsgroups(subset='test', categories=cats,shuffle=True, random_state=1,\n",
    "                             remove=('headers','footers', 'quotes'))     \n",
    "    clean_data(data_te.data)         \n",
    "    data_words = list(sent_to_words(cleaned))\n",
    "    te_data = lemmatization(data_words)\n",
    "\n",
    "#Fetch data and do some cleaning    \n",
    "def get_data():\n",
    "    train_data()\n",
    "    test_data()\n",
    "    \n",
    "#Get tfidf vectors    \n",
    "def get_tfidf():    \n",
    "    global tfidf_train,tfidf_test\n",
    "    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=3000,ngram_range=(1, 1),\n",
    "                                   stop_words='english')\n",
    "    tfidf_train = vectorizer.fit_transform(tr_data)\n",
    "    tfidf_test = vectorizer.transform(te_data) \n",
    "\n",
    "#get term frequency vectorizor\n",
    "def get_tfs():\n",
    "    global tf_train,tf_test\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=3000,ngram_range=(1, 1),stop_words='english') \n",
    "    tf_train = tf_vectorizer.fit_transform(tr_data)\n",
    "    tf_test = tf_vectorizer.transform(te_data)\n",
    "    \n",
    "#Vectorize data    \n",
    "def vectorize_data():\n",
    "    get_tfidf()\n",
    "    get_tfs()\n",
    "\n",
    "#Fetch clean and vectorized data\n",
    "def read_prep_data():\n",
    "    get_data()\n",
    "    vectorize_data()\n",
    "\n",
    "#Supervised classifier \n",
    "def run_supervised_classifier():\n",
    "    parameters = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'tfidf__max_features': (1000,2000,3000),\n",
    "               'clf__alpha': (1e-2, 1e-3)}\n",
    "    svm_clf = Pipeline([('tfidf', TfidfVectorizer()),('clf', SGDClassifier(loss='hinge',\n",
    "         random_state=42,max_iter=500,tol=1e-3))])\n",
    "    gs_clf = GridSearchCV(svm_clf, parameters, cv=5, iid=False, n_jobs=-1)\n",
    "    gs_clf = gs_clf.fit(tr_data,data_tr.target)\n",
    "    y_pred= gs_clf.predict(te_data)       \n",
    "    print('')\n",
    "    print(\"Supervised classification metrics\")\n",
    "    print(classification_report(data_te.target, y_pred, target_names=target_names))\n",
    "     \n",
    "    \n",
    "#Latent Dirichlet Allocation (LDA model)           \n",
    "def run_lda():      \n",
    "    lda_train = LatentDirichletAllocation(n_components=4, max_iter=100,\n",
    "                                learning_method='online',random_state=0) \n",
    "    lda_train.fit_transform(tf_train)\n",
    "    lda_test= lda_train.transform(tf_test)\n",
    "    lda_pred= lda_test.argmax(axis=1)\n",
    "    print('')\n",
    "    print(\"LDA classification metrics\")        \n",
    "    print(classification_report(data_te.target, lda_pred, target_names=target_names))\n",
    "      \n",
    "                    \n",
    "#Non-negative matrix factorization model  (NMF model)        \n",
    "def run_nnmf():\n",
    "    nnmf = NMF(n_components=4, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', init='nndsvda', max_iter=100, alpha=0.0,\n",
    "          l1_ratio=0.0)\n",
    "    nnmf_train= nnmf.fit_transform(tfidf_train)\n",
    "    nnmf_test = nnmf.transform(tfidf_test)\n",
    "    nnmf_pred= nnmf_test.argmax(axis=1)    \n",
    "    print('')\n",
    "    print(\"NMF classification metrics\")\n",
    "    print(classification_report(data_te.target, nnmf_pred, target_names=target_names))\n",
    "                  \n",
    "            \n",
    "#Baseline check on four labels in the unseen test data\n",
    "def check_baseline(): \n",
    "    ave_label_pc=[]\n",
    "    for i in range(4):\n",
    "        ave_label_pc.append(list(data_te.target).count(i)/data_te.target.shape[0])   \n",
    "        m= np.array(ave_label_pc).mean()\n",
    "    print(\"Baseline check(average percentage of the four labels in test data) :\", m)\n",
    "    print('')   \n",
    "        \n",
    "#Run unsupervised models\n",
    "def run_unsupervised_models():\n",
    "    run_lda() \n",
    "    run_nnmf()  \n",
    "\n",
    "#Main function compares supervised against the two unsupervised models(LDA, NMF)         \n",
    "def model_comparison():\n",
    "    read_prep_data()  \n",
    "    check_baseline()   \n",
    "    run_supervised_classifier()\n",
    "    run_unsupervised_models()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline check(average percentage of the four labels in test data) : 0.25\n",
      "\n",
      "\n",
      "Supervised classification metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Baseball       0.82      0.87      0.84       397\n",
      "      Hockey       0.91      0.89      0.90       399\n",
      "        Guns       0.85      0.85      0.85       364\n",
      " Middle East       0.88      0.85      0.86       376\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1536\n",
      "   macro avg       0.86      0.86      0.86      1536\n",
      "weighted avg       0.86      0.86      0.86      1536\n",
      "\n",
      "\n",
      "LDA classification metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Baseball       0.15      0.31      0.20       397\n",
      "      Hockey       0.47      0.61      0.53       399\n",
      "        Guns       0.36      0.14      0.20       364\n",
      " Middle East       0.02      0.00      0.00       376\n",
      "\n",
      "   micro avg       0.27      0.27      0.27      1536\n",
      "   macro avg       0.25      0.26      0.23      1536\n",
      "weighted avg       0.25      0.27      0.24      1536\n",
      "\n",
      "\n",
      "NMF classification metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Baseball       0.23      0.36      0.28       397\n",
      "      Hockey       0.55      0.76      0.64       399\n",
      "        Guns       0.12      0.04      0.06       364\n",
      " Middle East       0.85      0.51      0.64       376\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      1536\n",
      "   macro avg       0.44      0.42      0.40      1536\n",
      "weighted avg       0.44      0.43      0.41      1536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run main function to compare the models\n",
    "model_comparison()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
